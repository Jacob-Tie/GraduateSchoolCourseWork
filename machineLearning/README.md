# Brief description of all the files:
## PS1_jacobtiede.ipynb
In this file I implement K-nearest neighbors and apply it to a handwriting dataset.
## PS2_jacobtiede.ipynb
In this file I implement logistic regression using a basic gradient descent algorithm. This implementation also includes an all vs one method for training a multi-log regression model. This is applied on a handwriting dataset.
## PS3_jacobtiede.ipynb
In this file I implement lasso and ridge linear regressions from libraries, a support vector machine from a library, and finally a kernelized perceptron from scratch. This is then applied on a dataset of flower images.
## PS4_Jacob_Tiede
This homework assigment was an open ended Kaggle competition (not an official one, one created by our professor). It was to classify tabular data, and I used a combination of XGBoost and CatBoost to solve this problem.
## Homework5_Jacob_Tiede
Implementation of unsupervised clustering algorithms.
## The rest of the files
All the rest are data that can be used to reproduce my results.
